{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r ~/datasets/meetup/backup/CrudeOil ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../CrudeOil/CL=F_daily.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Close.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(data.Close).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = data.Close[~pd.isna(data.Close)]\n",
    "time_str = data.Date[~pd.isna(data.Close)]\n",
    "print(series.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 14\n",
    "delay = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train/Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.95\n",
    "split_time = int(len(data)*train_ratio)\n",
    "print(\"split_time_str: \", time_str.iloc[split_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = series[:split_time]\n",
    "x_valid = series[split_time-(window_size+delay):]\n",
    "x_forcast = series[-window_size:]\n",
    "print(x_train.shape, x_valid.shape, x_forcast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, label=\"train\")\n",
    "plt.plot(x_valid, label=\"valid\")\n",
    "plt.plot(x_forcast, label=\"forcast\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Windowed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer, delay=1, train=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + delay, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + delay))\n",
    "    if train:\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset = dataset.map(lambda window: (window[:window_size], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)  \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000\n",
    "\n",
    "time_str_train = time_str[(window_size+delay):split_time]\n",
    "time_str_valid = time_str[split_time:]\n",
    "print(time_str_train.shape, time_str_valid.shape)\n",
    "\n",
    "train_set = windowed_dataset(x_train, window_size, batch_size=128, shuffle_buffer=shuffle_buffer_size, delay=delay)\n",
    "valid_set = windowed_dataset(x_valid, window_size, batch_size=128, shuffle_buffer=shuffle_buffer_size, delay=delay, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(dataset):\n",
    "    count=0\n",
    "    for i,(x,y) in enumerate(dataset):\n",
    "        count+=x.shape[0]\n",
    "        if i==0:\n",
    "            print(\"x.shape: \", x.shape, \", y.shape: \", y.shape)\n",
    "    print(\"#records: \", count)\n",
    "    \n",
    "check_data(train_set)\n",
    "check_data(valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[None]),\n",
    "  tf.keras.layers.Lambda(lambda x: x / 100.0),\n",
    "  \"\"\"\n",
    "  add your code here!!\n",
    "  \"\"\"\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 100.0),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.squeeze(x, axis=-1) ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-4 * 10**(epoch / 20))\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=20, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for x,y in valid_set:\n",
    "    #print(x.shape, y.shape)\n",
    "    y_hat = model.predict(x)\n",
    "    #print(y_hat.shape, y_hat.dtype)\n",
    "    y_true += list(y)\n",
    "    y_pred = list(y_hat)\n",
    "\n",
    "time_index = list(x_valid[window_size+delay-1:].index)\n",
    "plt.plot(time_index, y_true, label=\"valid_true\",c=\"orange\")\n",
    "plt.plot(time_index, y_pred, label=\"valid_pred\",c=\"red\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcast_days = 200\n",
    "forcast_data = list(x_forcast.values)\n",
    "time_index = list(x_forcast.index)\n",
    "\n",
    "for day in range(forcast_days):\n",
    "    x = np.array(forcast_data[day:day+window_size])[np.newaxis]\n",
    "    y_hat = model.predict(x)\n",
    "    forcast_data.append(int(y_hat))\n",
    "    time_index.append(time_index[-1]+1)\n",
    "\n",
    "\n",
    "plt.plot(x_train, label=\"train\")\n",
    "plt.plot(x_valid, label=\"valid\")\n",
    "plt.plot(time_index, forcast_data, label=\"forcast_pred\")\n",
    "plt.legend()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, label=\"train\")\n",
    "plt.plot(x_valid, label=\"valid\")\n",
    "plt.plot(time_index[-forcast_days:], forcast_data[-forcast_days:], label=\"forcast_pred\")\n",
    "plt.xlim([2300,None])\n",
    "plt.legend()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
